# Models Directory

Trained machine learning models, scalers, and performance artifacts for MLB game outcome prediction.

## Overview

This directory contains all trained models and preprocessing objects from the game outcome prediction pipeline. Models are serialized using Python's `pickle` format for easy loading and deployment.

## Contents

### Trained Models (3 classifiers)

#### 1. `gb_model.pkl` - **Gradient Boosting** ⭐ (RECOMMENDED)
- **Type**: Gradient Boosting Classifier (scikit-learn)
- **Size**: 1.2 MB
- **Test Accuracy**: 54.63%
- **Precision**: 55.67%
- **Recall**: 62.10%
- **F1 Score**: 0.5871
- **ROC AUC**: 0.5495
- **Status**: ✅ Best performing model
- **Training Data**: 8,848 games (2020-2023)
- **Test Data**: 2,570 games (2024)

**Why choose Gradient Boosting?**
- Best test set accuracy among three models
- Good balance between precision and recall
- Reasonable file size for deployment
- Fast inference time
- Robust to outliers

#### 2. `rf_model.pkl` - **Random Forest**
- **Type**: Random Forest Classifier (scikit-learn)
- **Size**: 14 MB
- **Test Accuracy**: 54.01%
- **Precision**: 54.78%
- **Recall**: 65.62%
- **F1 Score**: 0.5971
- **ROC AUC**: 0.5446
- **Status**: ✅ Good alternative
- **Parameters**: 100 estimators, max_depth=15
- **Note**: Larger file size, good recall

**Use when**: High recall needed (catch more home wins)

#### 3. `lr_model.pkl` - **Logistic Regression**
- **Type**: Logistic Regression (scikit-learn)
- **Size**: 778 bytes
- **Test Accuracy**: 54.05%
- **Precision**: 54.11%
- **Recall**: 75.88%
- **F1 Score**: 0.6317
- **ROC AUC**: 0.5640
- **Status**: ✅ Lightweight option
- **Parameters**: max_iter=1000, random_state=42
- **Note**: Smallest file size, highest recall

**Use when**: File size critical or interpretability needed

### Preprocessing Objects

#### `scaler.pkl` - Feature Standardization
- **Type**: StandardScaler (scikit-learn)
- **Size**: 878 bytes
- **Purpose**: Standardize features to mean=0, std=1
- **Used by**: Logistic Regression model only
- **Features Scaled**: 9 features
  - home_historical_wr
  - away_historical_wr
  - home_avg_score
  - away_avg_score
  - days_into_season
  - home_field_advantage
  - home_recent_form
  - day_of_week
  - month

**Important**: Only needed when using `lr_model.pkl`

#### `feature_names.pkl` - Column Names
- **Type**: List of strings
- **Size**: Minimal
- **Purpose**: Map feature indices to names
- **Content**: 9 feature names
- **Usage**: Prevent sklearn validation warnings when predicting

**Usage Example**:
```python
import pickle
import pandas as pd

# Load model and feature names
with open('models/gb_model.pkl', 'rb') as f:
    model = pickle.load(f)
with open('models/feature_names.pkl', 'rb') as f:
    features = pickle.load(f)

# Create DataFrame with proper column names
X = pd.DataFrame(data, columns=features)

# Predict (no warnings!)
predictions = model.predict(X)
```

### Visualization

#### `model_performance.png`
- **Type**: PNG image chart
- **Size**: 136 KB
- **Contents**: 4-panel visualization
  1. Model performance comparison (accuracy, precision, recall, F1)
  2. ROC curves for all three models
  3. Feature importance (Random Forest)
  4. Prediction probability distribution (Gradient Boosting)
- **Purpose**: Visual summary of model performance
- **Generated by**: `src/train_model.py`

### Legacy Models

#### `baseball_model_xgb.pkl` - **XGBoost** (DEPRECATED)
- **Type**: XGBoost Classifier (legacy)
- **Size**: 83 KB
- **Status**: ⚠️ Not used in current pipeline
- **Note**: Kept for reference/comparison

## Model Comparison

| Metric | Logistic Regression | Random Forest | Gradient Boosting |
|--------|-------------------|----------------|-------------------|
| Accuracy | 54.05% | 54.01% | **54.63%** ✓ |
| Precision | 54.11% | 54.78% | 55.67% |
| Recall | 75.88% | 65.62% | 62.10% |
| F1 Score | 0.6317 | 0.5971 | 0.5871 |
| ROC AUC | 0.5640 | 0.5446 | 0.5495 |
| File Size | 778 B | 14 MB | 1.2 MB |
| Inference Speed | Fastest | Medium | Medium |

## Feature Importance

**Ranked by Gradient Boosting model:**

| Rank | Feature | Importance | Type |
|------|---------|-----------|------|
| 1 | home_historical_wr | 17.54% | Team strength |
| 2 | home_field_advantage | 16.05% | Advantage |
| 3 | away_avg_score | 15.71% | Opponent scoring |
| 4 | home_avg_score | 15.53% | Home scoring |
| 5 | away_historical_wr | 15.40% | Opponent strength |
| 6 | days_into_season | 9.20% | Season progression |
| 7 | home_recent_form | 4.86% | Recent performance |
| 8 | day_of_week | 4.12% | Schedule effect |
| 9 | month | 1.60% | Seasonal trend |

## How to Use Models

### Loading & Prediction

```python
import pickle
import pandas as pd

# Load the best model
with open('models/gb_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Prepare feature DataFrame
features = pd.DataFrame({
    'home_historical_wr': [0.55],
    'away_historical_wr': [0.50],
    'home_avg_score': [4.5],
    'away_avg_score': [4.3],
    'days_into_season': [150],
    'home_field_advantage': [0.08],
    'home_recent_form': [0.60],
    'day_of_week': [2],
    'month': [7]
})

# Make prediction
prediction = model.predict(features)  # 1=home win, 0=away win
probability = model.predict_proba(features)[0, 1]  # P(home win)

print(f"Prediction: {'HOME WIN' if prediction[0] else 'AWAY WIN'}")
print(f"Confidence: {probability:.2%}")
```

### With Feature Scaling (Logistic Regression)

```python
import pickle
import pandas as pd

# Load model and scaler
with open('models/lr_model.pkl', 'rb') as f:
    model = pickle.load(f)
with open('models/scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

# Prepare features
features = pd.DataFrame({...})

# Scale features
features_scaled = scaler.transform(features)

# Predict
prediction = model.predict(features_scaled)
probability = model.predict_proba(features_scaled)[0, 1]
```

### Batch Predictions

```python
import pickle
import pandas as pd

model = pickle.load(open('models/gb_model.pkl', 'rb'))

# Load multiple games
games = pd.read_csv('upcoming_games.csv')

# Make predictions for all
predictions = model.predict(games[feature_columns])
probabilities = model.predict_proba(games[feature_columns])[:, 1]

# Add to DataFrame
games['prediction'] = ['HOME' if p else 'AWAY' for p in predictions]
games['confidence'] = probabilities

print(games[['home_team', 'away_team', 'prediction', 'confidence']])
```

## Model Performance Details

### Accuracy by Season (2024 Test Set)
- Average: 54.63%
- Baseline (random): 50.00%
- Improvement: +4.63 percentage points

### Top-50% Confidence Predictions
- Accuracy on confident predictions: ~58%
- Threshold: probability > 0.54

### Key Insights
- Home field advantage is predictive (52.9% baseline win rate)
- Team historical performance matters most
- Recent form (last 10 games) helps
- Day of week and month have minor effect

## Model Retraining

To retrain models with new data:

```bash
# Update data first
python -m src.scraper

# Retrain models
python -m src.train_model
```

This will:
1. Load all game data
2. Engineer features
3. Train all three models
4. Save new pickle files
5. Update visualization
6. Overwrite existing models

## Deployment Notes

**File Size Considerations:**
- `gb_model.pkl` (1.2 MB): Recommended for production
- `lr_model.pkl` (778 B): For size-constrained environments
- `rf_model.pkl` (14 MB): Not recommended for mobile/edge

**Inference Speed:**
- Logistic Regression: ~1ms per prediction
- Gradient Boosting: ~5ms per prediction
- Random Forest: ~10ms per prediction

**Dependencies:**
- scikit-learn >= 1.0
- pandas >= 1.3
- numpy >= 1.20

## Troubleshooting

**"X does not have valid feature names" warning**
- ✓ Fixed in current version (feature_names.pkl)
- Create DataFrame with named columns: `pd.DataFrame(data, columns=feature_names)`

**Model prediction returns wrong shape**
- Ensure input is 2D array/DataFrame: `X.reshape(-1, 9)` or use DataFrame

**File not found errors**
- Models must be in `models/` directory (relative to working directory)
- Use absolute paths: `Path(__file__).parent / 'models'`

---

**Status**: ✅ Production-ready  
**Last Updated**: February 4, 2026  
**Training Data**: 11,486 games (2020-2024)  
**Best Model**: Gradient Boosting (gb_model.pkl)
